{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fffcf00",
   "metadata": {},
   "source": [
    "<p>A season in the English Premiere League typically runs between August and May and contains 38 games. Each team plays every other team twice, once at home and once away. For a win, a team is awarded 3 points; for a draw, both teams are awarded one point; and, for a loss, a team receives no points. At the end of the season the team with the most points is crowned Premier League Champion</p>\n",
    "\n",
    "<p>Journalists, pundits, and fans all like to read deeply into teams' performances and make predictive statements about how certain results will affect the rest of their side's season. How will a team react to a particularly bad loss? Will a late evening game leave them tired for subsequent fixtures? Can they do it on a cold rainy night in Stoke?</p>\n",
    "\n",
    "<p>For every such question there are at least a dozen answers. After pulling data for the last few years of Premier League results, I attempted to statistically verify several of these kinds of claims.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071cf2e2",
   "metadata": {},
   "source": [
    "<p>First, some imports:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a75181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import colorsys\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a85201e",
   "metadata": {},
   "source": [
    "<p>The data I used comes from a publicly available API hosted on rapid API: api-sports' API-FOOTBALL. I used the fixtures endpoint to retrieve data for an entire season. The data arrives fairly deeply nested, so I wrote a recursive function to unroll any complex types into individual rows.</p>\n",
    "\n",
    "<h4>If you want to use your own rapid API key, you must sign up for API-FOOTBALL in rapid API. Usage of the API may incur charges as outlined on their fee page</h4>\n",
    "\n",
    "<p>If you have a rapid API key, you can use it to replace the definitions below and get the data from the actual endpoint. Otherwise, the code will fall back to some cached data provided in the repo. Note that the cached data only goes as far back as the 2011-12 season.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_rapid_api_key() -> str:\n",
    "    with open(os.path.abspath('../api_keys/rapid_api_key.txt')) as file:\n",
    "        api_key = file.read()\n",
    "    return api_key\n",
    "\n",
    "\n",
    "def _flatten_response(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes a DataFrame with dictionary values and \"unrolls\" them such that each dictionary entry receives its own column.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame to flatten\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Flat DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    df_types: pd.Series = df.iloc[0].apply(type)\n",
    "    df_types = df_types.reset_index().rename({'index': 'column_name', 0: 'column_type'}, axis=1)\n",
    "    dict_columns = df_types[df_types['column_type'] == dict]['column_name']\n",
    "    if len(dict_columns) > 0:\n",
    "        for col_name in dict_columns:\n",
    "            new_cols = df[col_name].apply(pd.Series)\n",
    "            new_col_names = {new_col_name: f'{col_name}-{new_col_name}' for new_col_name in new_cols.columns}\n",
    "            new_cols = new_cols.rename(new_col_names, axis=1)\n",
    "            df = pd.concat([df, new_cols], axis=1)\n",
    "            df = df.drop(col_name, axis=1)\n",
    "        df = _flatten_response(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_season_data(season: int, league_id: int, use_cache=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gets the historical data for a given season and soccer league\n",
    "\n",
    "    Args:\n",
    "        season (int): Season for which to get data\n",
    "        league_id (str): League for which to get data\n",
    "        use_cache (bool): Whether to use local cache or not\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Historical data for the league in the given season\n",
    "\n",
    "    \"\"\"\n",
    "    cache_dir = os.path.abspath(f'../local_cache/')\n",
    "    cache_file_path = f'{cache_dir}/league_{league_id}_season_{season}.csv'\n",
    "\n",
    "    if use_cache:\n",
    "        print('Retrieving data from local cache')\n",
    "        file_already_exists = os.path.exists(cache_file_path)\n",
    "\n",
    "        if file_already_exists:\n",
    "            return pd.read_csv(cache_file_path)\n",
    "\n",
    "    print('Retrieving data from API')\n",
    "    api_key = _get_rapid_api_key()\n",
    "\n",
    "    url = \"https://api-football-v1.p.rapidapi.com/v3/fixtures\"\n",
    "\n",
    "    querystring = {\"league\": league_id, \"season\": season}\n",
    "\n",
    "    headers = {\n",
    "        'x-rapidapi-host': \"api-football-v1.p.rapidapi.com\",\n",
    "        'x-rapidapi-key': api_key\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "    df = pd.DataFrame(json.loads(response.text)['response'])\n",
    "\n",
    "    df = _flatten_response(df)\n",
    "\n",
    "    if use_cache:\n",
    "        print('Saving data to local cache')\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        df.to_csv(cache_file_path)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b173140",
   "metadata": {},
   "source": [
    "<p>The cell below calls the functions listed above to get data for the specified years. You can change the years as desired, just note that I haven't defined team color data for teams outside of the 2018 season. Some visualizations might look off if you try to use other seasons' data.</p>\n",
    "\n",
    "<h3>I've also found that older EPL data has some missing fields that cause the visualizations to break. Anything after and including 2011 seems to be fine</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epl_league_id = 39\n",
    "fixtures_df = get_season_data(2014, epl_league_id, use_cache=True)\n",
    "fixtures_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c675f8",
   "metadata": {},
   "source": [
    "<p>The DataFrame above has one row per fixture, though ideally we'd want a DataFrame that tracks a team's overall position in the league throughout a season. The functions below reshape and aggregate the fixtures data into more table-centric data, where each row is more akin to an entry in a league table for a particular match week. As a result the generated DataFrame has twice as many rows as the original since both the home team and away team for a match get their own row.</p>\n",
    "\n",
    "<p>During this transformation I also add some columns used for visualization, namely I add the color used to represent each team and a three letter code. I hand-picked the colors for the 2018-19 season, originally intending to analyze just that year. I quickly found that there weren't enough samples for a lot of the cases I was trying to test. Instead of hand-picking a bunch more colors for various promoted/relegated teams, I wrote a function to download the team's logo and use the most common color determined by pixel count as the team's color. It works well enough for most teams, just be aware that if a team has a weird color in a graph then  it's probably for that reason.</p>\n",
    "\n",
    "\n",
    "<p>I also define a method to take get and create multiple seasons worth of table data in one go. The function concatenates all the data together into one DataFrame. This puts all the data I'll be working on later in one place.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_colors = {\n",
    "    42: '#fe0002',\n",
    "    35: '#d71a21',\n",
    "    51: '#0054a6',\n",
    "    44: '#6a003a',\n",
    "    43: '#093ad6',\n",
    "    49: '#0a4595',\n",
    "    52: '#eb302e',\n",
    "    45: '#00369c',\n",
    "    36: '#000000',\n",
    "    37: '#0361af',\n",
    "    46: '#273e8a',\n",
    "    40: '#e31b23',\n",
    "    50: '#6caee0',\n",
    "    33: '#d81920',\n",
    "    34: '#383838',\n",
    "    41: '#d71920',\n",
    "    47: '#001c58',\n",
    "    38: '#ffee00',\n",
    "    48: '#7d2c3b',\n",
    "    39: '#f9a01b'\n",
    "}\n",
    "\n",
    "\n",
    "def get_team_colors_from_api(matches_df: pd.DataFrame, use_cache=False, league_id=None, season=None,\n",
    "                             rebuild_cache=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gets a dictionary of team colors by finding the most common pixel color in the teams' logo\n",
    "\n",
    "    Requests a 256 x 256 PNG image for each team using the API-Football API\n",
    "\n",
    "    Args:\n",
    "        matches_df (DataFrame): DataFrame acquired using the get_season_data function\n",
    "        use_cache (bool): Optional parameter specifying whether to use cached data if it is available. Cache\n",
    "            is granular down to the league/season combination. Must specify league_id and season to use the\n",
    "            cache\n",
    "        league_id (int): League id for the team colors to retrieve\n",
    "        season (int): Season for the team colors to retrieve\n",
    "        rebuild_cache (bool): If true, will recreate data using the API and overwrite any existing cached data with\n",
    "            the new values\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame where the index is team ids and the only column is team_color containing\n",
    "            team color values as hex colors\n",
    "    \"\"\"\n",
    "    cache_dir = os.path.abspath(f'../local_cache/')\n",
    "    cache_file_path = f'{cache_dir}/league_{league_id}_season_{season}_color_data.csv'\n",
    "\n",
    "    if use_cache and not rebuild_cache:\n",
    "        if league_id is None or season is None:\n",
    "            raise RuntimeError('One of league_id or season is None when attempting to use colors cache!')\n",
    "\n",
    "        file_already_exists = os.path.exists(cache_file_path)\n",
    "\n",
    "        if file_already_exists:\n",
    "            print('Retrieving color data from local cache')\n",
    "            return pd.read_csv(cache_file_path, index_col='team_id')\n",
    "\n",
    "    def get_nth_most_common_color(colors: list, n: int):\n",
    "        \"\"\"\n",
    "        Finds and returns the nth most common color in a list of colors in HLS format\n",
    "\n",
    "        Args:\n",
    "            colors: List of colors in RGB format\n",
    "            n: Rank of the color to get ordered by descending frequency\n",
    "\n",
    "        Returns:\n",
    "            Tuple: Tuple containing hue, saturation, lightness in that order\n",
    "        \"\"\"\n",
    "        colors.sort(key=lambda color: color[0])\n",
    "        most_common_color = colors[-n][-1]\n",
    "        most_common_color_hls = colorsys.rgb_to_hsv(most_common_color[0], most_common_color[1],\n",
    "                                                    most_common_color[2])\n",
    "        return most_common_color_hls[0], most_common_color_hls[1], most_common_color_hls[2]\n",
    "\n",
    "    def get_colors(df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Finds the most common color in a team's logo. Uses HSV color system to filter out low saturation colors\n",
    "            that are likely to be background pixels. Doesn't always return the best color to represent a team\n",
    "            but is usually pretty decent. Best used as a fallback option when a hand-picked value isn't available.\n",
    "\n",
    "        Args:\n",
    "            df (DataFrame): DataFrame containing at least a teams-home-logo column with URLs pointing to team logo\n",
    "                image files served by API-FOOTBALL in Rapid API and a teams-home-id containing a team id.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: DataFrame indexed by team id with a column named team_color containing the hex value\n",
    "                of the most common pixel found in the team's logo.\n",
    "        \"\"\"\n",
    "        logo_url = df.iloc[0]['teams-home-logo']\n",
    "        with urllib.request.urlopen(logo_url) as image_url_in:\n",
    "            image_file = io.BytesIO(image_url_in.read())\n",
    "        image = Image.open(image_file)\n",
    "        image: Image\n",
    "\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "        image_colors = image.getcolors(image.size[0] * image.size[1])\n",
    "        image_colors.sort(key=lambda color: color[0])\n",
    "\n",
    "        current_rank = 1\n",
    "        h, s, v = get_nth_most_common_color(image_colors, current_rank)\n",
    "        while s < 0.35:\n",
    "            current_rank += 1\n",
    "            h, s, v = get_nth_most_common_color(image_colors, current_rank)\n",
    "\n",
    "        rgb_color_to_use = colorsys.hsv_to_rgb(h, s, v)\n",
    "        return '#%02x%02x%02x' % \\\n",
    "               (round(rgb_color_to_use[0]), round(rgb_color_to_use[1]), round(rgb_color_to_use[2]))\n",
    "\n",
    "    colors_df = matches_df.groupby(by='teams-home-id') \\\n",
    "        .apply(get_colors) \\\n",
    "        .to_frame() \\\n",
    "        .rename({0: 'team_color'}, axis=1)\n",
    "\n",
    "    colors_df.index.rename('team_id', inplace=True)\n",
    "\n",
    "    if use_cache or rebuild_cache:\n",
    "        print('Saving color data to local cache')\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        colors_df.to_csv(cache_file_path)\n",
    "\n",
    "    return colors_df\n",
    "\n",
    "\n",
    "def create_tables_df(matches_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    matches_df['round'] = matches_df['league-round'].apply(lambda s: int(s.split('Regular Season - ')[1]))\n",
    "\n",
    "    matches_df['home_win'] = matches_df['score-fulltime-home'] > matches_df['score-fulltime-away']\n",
    "    matches_df['away_win'] = matches_df['score-fulltime-home'] < matches_df['score-fulltime-away']\n",
    "    matches_df['draw'] = matches_df['score-fulltime-home'] == matches_df['score-fulltime-away']\n",
    "\n",
    "    matches_df['home_pts'] = matches_df['home_win'] * 3 + matches_df['draw'] * 1\n",
    "    matches_df['away_pts'] = matches_df['away_win'] * 3 + matches_df['draw'] * 1\n",
    "\n",
    "    matches_df['home_gd_half_time'] = matches_df['score-halftime-home'] - matches_df['score-halftime-away']\n",
    "    matches_df['away_gd_half_time'] = -matches_df['home_gd_half_time']\n",
    "\n",
    "    matches_df['home_gd_full_time'] = matches_df['score-fulltime-home'] - matches_df['score-fulltime-away']\n",
    "    matches_df['away_gd_full_time'] = -matches_df['home_gd_full_time']\n",
    "\n",
    "    relevant_cols = ['round', 'teams-home-id', 'teams-home-name', 'teams-away-id', 'teams-away-name',\n",
    "                     'score-halftime-home', 'score-halftime-away', 'score-fulltime-home', 'score-fulltime-away',\n",
    "                     'home_win', 'away_win', 'draw', 'home_pts', 'away_pts', 'home_gd_half_time', 'away_gd_half_time',\n",
    "                     'home_gd_full_time', 'away_gd_full_time', 'league-id', 'league-season', 'teams-home-logo',\n",
    "                     'fixture-date']\n",
    "    matches_df = matches_df[relevant_cols]\n",
    "\n",
    "    home_match_results_df = matches_df[['round', 'teams-home-id', 'teams-home-name', 'teams-away-id', 'teams-away-name',\n",
    "                                        'home_win', 'draw', 'home_pts', 'home_gd_half_time', 'home_gd_full_time',\n",
    "                                        'league-id', 'league-season', 'fixture-date']] \\\n",
    "        .rename({'teams-home-id': 'team_id', 'teams-home-name': 'team_name', 'teams-away-id': 'opp_team_id',\n",
    "                 'teams-away-name': 'opp_team_name', 'home_win': 'match_win', 'home_pts': 'match_pts',\n",
    "                 'home_gd_half_time': 'match_gd_half', 'home_gd_full_time': 'match_gd_full',\n",
    "                 'draw': 'match_draw', 'league-id': 'league_id', 'league-season': 'league_season',\n",
    "                 'fixture-date': 'fixture_date'}, axis='columns')\n",
    "    home_match_results_df['home'] = True\n",
    "\n",
    "    away_match_results_df = matches_df[['round', 'teams-home-id', 'teams-home-name', 'teams-away-id', 'teams-away-name',\n",
    "                                        'away_win', 'draw', 'away_pts', 'away_gd_half_time', 'away_gd_full_time',\n",
    "                                        'league-id', 'league-season', 'fixture-date']] \\\n",
    "        .rename({'teams-away-id': 'team_id', 'teams-away-name': 'team_name', 'teams-home-id': 'opp_team_id',\n",
    "                 'teams-home-name': 'opp_team_name', 'away_win': 'match_win', 'away_pts': 'match_pts',\n",
    "                 'away_gd_half_time': 'match_gd_half', 'away_gd_full_time': 'match_gd_full',\n",
    "                 'draw': 'match_draw', 'league-id': 'league_id', 'league-season': 'league_season',\n",
    "                 'fixture-date': 'fixture_date'}, axis='columns')\n",
    "    away_match_results_df['home'] = False\n",
    "\n",
    "    tables_df = pd.concat([home_match_results_df, away_match_results_df], axis='rows') \\\n",
    "        .sort_values(by='round') \\\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    cumulative_stats = tables_df[['team_id', 'match_win', 'match_draw', 'match_pts', 'match_gd_half',\n",
    "                                  'match_gd_full']] \\\n",
    "        .groupby(by='team_id').cumsum() \\\n",
    "        .rename({'match_win': 'wins', 'match_draw': 'draws', 'match_pts': 'pts', 'match_gd_half': 'gd_half',\n",
    "                 'match_gd_full': 'gd_full'}, axis='columns')\n",
    "\n",
    "    tables_df = pd.concat([tables_df, cumulative_stats], axis='columns')\n",
    "    tables_df['losses'] = tables_df['round'] - tables_df['wins'] - tables_df['draws']\n",
    "\n",
    "    tables_df['fixture_date'] = tables_df['fixture_date'].apply(datetime.datetime.fromisoformat)\n",
    "\n",
    "    team_colors_from_api = get_team_colors_from_api(matches_df, use_cache=True, league_id=tables_df['league_id'][0],\n",
    "                                                    season=tables_df['league_season'][0])\n",
    "\n",
    "    def get_team_color(row: pd.Series, row_team_id_col_name: str) -> str:\n",
    "        if row[row_team_id_col_name] in team_colors:\n",
    "            return team_colors[row[row_team_id_col_name]]\n",
    "        else:\n",
    "            return team_colors_from_api.loc[row[row_team_id_col_name]]['team_color']\n",
    "\n",
    "    tables_df['team_color'] = tables_df.apply(get_team_color, row_team_id_col_name='team_id', axis='columns')\n",
    "    tables_df['opp_team_color'] = tables_df.apply(get_team_color, row_team_id_col_name='opp_team_id', axis='columns')\n",
    "\n",
    "    return tables_df\n",
    "\n",
    "\n",
    "def validate_tables_df(tables_df: pd.DataFrame):\n",
    "    n_rounds = max(tables_df['round'])\n",
    "    n_teams = tables_df['team_id'].nunique(dropna=True)\n",
    "\n",
    "    n_rows_expected = n_rounds * n_teams\n",
    "\n",
    "    if len(tables_df) != n_rows_expected:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def create_multi_season_tables_df(start_year: int, end_year: int, league_id: int, throw_on_invalid=True,\n",
    "                                  use_cache=True):\n",
    "    \"\"\"\n",
    "    Gets all the season data for a range of years and return the results as one big DataFrame\n",
    "\n",
    "    Args:\n",
    "        start_year: Start of the range inclusive\n",
    "        end_year: End of the range inclusive\n",
    "        league_id: Id for the league\n",
    "        throw_on_invalid: If true will throw an error if any season data fails validation. If false will omit\n",
    "            the data and still return\n",
    "        use_cache: Whether or not to prioritize the local cache when getting data\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Pandas DataFrame with multiple seasons of league table data\n",
    "\n",
    "    \"\"\"\n",
    "    multi_season_table_df = pd.DataFrame()\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        current_season_df = create_tables_df(get_season_data(season=year, league_id=league_id, use_cache=use_cache))\n",
    "        is_season_valid = validate_tables_df(current_season_df)\n",
    "        if not is_season_valid and throw_on_invalid:\n",
    "            raise RuntimeError(f'Season {year} league {league_id} failed validation!')\n",
    "        elif is_season_valid:\n",
    "            multi_season_table_df = pd.concat([multi_season_table_df, current_season_df])\n",
    "            \n",
    "    def create_final_position_column(season_df: pd.DataFrame):\n",
    "        final_round_df = season_df.loc[season_df['round'] == max(season_df['round'])] \\\n",
    "            .sort_values(by=['pts', 'gd_full'], ascending=True)\n",
    "        final_round_df['final_position'] = final_round_df['pts'].rank(method='first').astype(int)\n",
    "        final_round_df = final_round_df.reset_index(drop=True)\n",
    "\n",
    "        season_df = season_df.reset_index(drop=True)\n",
    "        season_df = season_df.merge(final_round_df[['team_id', 'final_position']], on='team_id')\n",
    "\n",
    "        return season_df\n",
    "\n",
    "    multi_season_table_df = multi_season_table_df.groupby('league_season').apply(create_final_position_column)\n",
    "\n",
    "    return multi_season_table_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b85365",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_df = create_multi_season_tables_df(2011, 2021, epl_league_id)\n",
    "tables_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ec078",
   "metadata": {},
   "source": [
    "<p>This data shape is much easier to work with. Using this I can create a simple visualization of each teams' points haul throughout the season with bokeh:</p>\n",
    "\n",
    "<h3>When running the cells below, please make sure that the port number in the notebook_url variable matches the port number displayed in your web browser's address bar, or bokeh will throw an error.</h3>\n",
    "<p>In most cases the notebook will be running on port 8888, but if you have multiple notebook instances open then this could change. Also feel free to adjust the plot_size variable to best suit your monitor and browser. Each visualization is intended to be fully in frame without any need for scrolling.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2cf0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "\n",
    "notebook_url = 'http://localhost:8888'\n",
    "\n",
    "plot_size = 400\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab045d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, LabelSet, VBar, Legend, MultiLine, Slider, DataTable, Dropdown, FactorRange, Range1d\n",
    "from bokeh.layouts import row, column\n",
    "from functools import partial\n",
    "\n",
    "import math\n",
    "\n",
    "selected_year = max(tables_df['league_season'])\n",
    "selected_round = min(tables_df.loc[tables_df['league_season'] == selected_year]['round'])\n",
    "\n",
    "\n",
    "def slider_update(attr, old, new, lines_data_source, bar_data_source):\n",
    "    update_round_df = tables_df.loc[(tables_df['round'] == new) & \n",
    "                                    (tables_df['league_season'] == selected_year)].reset_index(drop=True)\n",
    "    update_round_df = update_round_df.sort_values(by='final_position')\n",
    "\n",
    "    bar_data_source.data['x'] = update_round_df['team_name']\n",
    "    bar_data_source.data['y'] = [0] * len(update_round_df)\n",
    "    bar_data_source.data['top'] = update_round_df['pts']\n",
    "    bar_data_source.data['color'] = update_round_df['team_color']\n",
    "    bar_data_source.data['label'] = update_round_df['team_name']\n",
    "\n",
    "    update_tables_till_current_round_df = tables_df.loc[(tables_df['league_season'] == selected_year) &\n",
    "                                                         (tables_df['round'] <= new)]\n",
    "\n",
    "    new_xs = list()\n",
    "    new_ys = list()\n",
    "    new_team_colors = list()\n",
    "    new_team_name = list()\n",
    "\n",
    "    for update_team_name in update_round_df['team_name']:\n",
    "        update_team_df = update_tables_till_current_round_df.loc[\n",
    "            update_tables_till_current_round_df['team_name'] == update_team_name]\n",
    "        update_team_color = update_team_df['team_color'].iloc[0]\n",
    "\n",
    "        new_xs.append(update_team_df['round'])\n",
    "        new_ys.append(update_team_df['pts'])\n",
    "\n",
    "        new_team_colors.append(update_team_color)\n",
    "        new_team_name.append(update_team_name)\n",
    "\n",
    "    lines_data_source.data['xs'] = new_xs\n",
    "    lines_data_source.data['ys'] = new_ys\n",
    "    lines_data_source.data['team_colors'] = new_team_colors\n",
    "    lines_data_source.data['team_name'] = new_team_name\n",
    "    \n",
    "\n",
    "def year_selector_update(event, lines_data_source, bar_data_source, bar_graph_object, line_graph_object, round_slider_object):\n",
    "    new_year = int(event.item)\n",
    "    global selected_year\n",
    "    selected_year = new_year\n",
    "    \n",
    "    update_season_df = tables_df.loc[tables_df['league_season'] == new_year].reset_index(drop=True)\n",
    "    update_round_df = update_season_df.loc[update_season_df['round'] == 1].reset_index(drop=True)\n",
    "    update_round_df = update_round_df.sort_values(by='final_position')\n",
    "    \n",
    "    bar_graph_object.x_range.factors = update_round_df['team_name'].unique().tolist()\n",
    "    \n",
    "    bar_graph_object.y_range.end = max(update_season_df['pts']) + 10\n",
    "    line_graph_object.y_range.end = max(update_season_df['pts']) + 10\n",
    "\n",
    "    bar_graph_object.title.text = f'{new_year} Season Points Progression'\n",
    "\n",
    "    bar_data_source.data['x'] = update_round_df['team_name']\n",
    "    bar_data_source.data['y'] = [0] * len(update_round_df)\n",
    "    bar_data_source.data['top'] = update_round_df['pts']\n",
    "    bar_data_source.data['color'] = update_round_df['team_color']\n",
    "    bar_data_source.data['label'] = update_round_df['team_name']\n",
    "\n",
    "    update_tables_till_current_round_df = update_season_df.loc[update_season_df['round'] <= 1]\n",
    "\n",
    "    new_xs = list()\n",
    "    new_ys = list()\n",
    "    new_team_colors = list()\n",
    "    new_team_name = list()\n",
    "\n",
    "    for update_team_name in update_round_df['team_name']:\n",
    "        update_team_df = update_tables_till_current_round_df.loc[\n",
    "            update_tables_till_current_round_df['team_name'] == update_team_name]\n",
    "        update_team_color = update_team_df['team_color'].iloc[0]\n",
    "\n",
    "        new_xs.append(update_team_df['round'])\n",
    "        new_ys.append(update_team_df['pts'])\n",
    "\n",
    "        new_team_colors.append(update_team_color)\n",
    "        new_team_name.append(update_team_name)\n",
    "\n",
    "    lines_data_source.data['xs'] = new_xs\n",
    "    lines_data_source.data['ys'] = new_ys\n",
    "    lines_data_source.data['team_colors'] = new_team_colors\n",
    "    lines_data_source.data['team_name'] = new_team_name\n",
    "    \n",
    "    round_slider_object.value = 1\n",
    "    round_slider_object.trigger(new=1, old=None, attr='value')\n",
    "\n",
    "\n",
    "def create_bokeh_plot_for_round(tables_df: pd.DataFrame, round_num: int, plot_size=400):\n",
    "    tables_df = tables_df.sort_values(by=['round', 'pts', 'team_id'], ascending=[True, False, True])\n",
    "    \n",
    "    season_df = tables_df.loc[tables_df['league_season'] == selected_year]\n",
    "    round_df = season_df.loc[tables_df['round'] == round_num].reset_index(drop=True)\n",
    "    \n",
    "    round_df = round_df.sort_values(by='pts', ascending=True)\n",
    "\n",
    "    line_graph = figure(x_range=(0, max(tables_df['round'])),\n",
    "                        y_range=(0, max(tables_df['pts']) + 10),\n",
    "                        x_axis_label='Round',\n",
    "                        y_axis_label='Points',\n",
    "                        toolbar_location=None,\n",
    "                        plot_width=plot_size,\n",
    "                        plot_height=plot_size)\n",
    "\n",
    "    line_graph.toolbar.active_drag = None\n",
    "    line_graph.toolbar.active_scroll = None\n",
    "    line_graph.toolbar.active_tap = None\n",
    "\n",
    "    line_graph.y_range.start = 0\n",
    "\n",
    "    line_graph.xgrid.grid_line_color = None\n",
    "    \n",
    "    final_round_df = season_df.loc[season_df['round'] == max(season_df['round'])]\n",
    "\n",
    "    bar_graph = figure(title=f'{selected_year} Season Points Progression',\n",
    "                       y_axis_label='Points',\n",
    "                       x_range=final_round_df.sort_values(by='final_position', ascending=True)['team_name'],\n",
    "                       y_range=(0, max(tables_df['pts']) + 10),\n",
    "                       toolbar_location=None,\n",
    "                       plot_width=plot_size,\n",
    "                       plot_height=plot_size)\n",
    "\n",
    "    bar_graph.toolbar.active_drag = None\n",
    "    bar_graph.toolbar.active_scroll = None\n",
    "    bar_graph.toolbar.active_tap = None\n",
    "\n",
    "    bar_graph.y_range.start = 0\n",
    "\n",
    "    bar_graph.xgrid.grid_line_color = None\n",
    "\n",
    "    bar_graph.xaxis.major_label_orientation = (5. * math.pi) / 12.\n",
    "\n",
    "    bar_data_source = ColumnDataSource(\n",
    "        dict(\n",
    "            x=round_df['team_name'],\n",
    "            y=[0] * len(round_df),\n",
    "            top=round_df['pts'],\n",
    "            color=round_df['team_color'],\n",
    "            label=round_df['team_name']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    tables_till_current_round_df = tables_df.loc[tables_df['round'] <= round_num]\n",
    "\n",
    "    xs = list()\n",
    "    ys = list()\n",
    "    team_colors = list()\n",
    "    team_name_list = list()\n",
    "\n",
    "    for team_name in round_df['team_name']:\n",
    "        round_df = round_df.sort_values(by='final_position')\n",
    "        team_df = tables_till_current_round_df.loc[tables_till_current_round_df['team_name'] == team_name]\n",
    "        team_color = team_df['team_color'].iloc[0]\n",
    "\n",
    "        xs.append(team_df['round'])\n",
    "        ys.append(team_df['pts'])\n",
    "        team_colors.append(team_color)\n",
    "        team_name_list.append(team_name)\n",
    "\n",
    "    lines_data_source = ColumnDataSource(\n",
    "        dict(\n",
    "            xs=xs,\n",
    "            ys=ys,\n",
    "            team_colors=team_colors,\n",
    "            team_name=team_name_list\n",
    "        )\n",
    "    )\n",
    "\n",
    "    bar_graph.vbar(x='x', top='top', color='color', source=bar_data_source)\n",
    "    line_graph.multi_line(xs='xs', ys='ys', line_color='team_colors', line_width=2, source=lines_data_source)\n",
    "\n",
    "    round_slider = Slider(start=1, end=max(tables_df['round']), value=1, step=1, title='Round')\n",
    "    year_labels = [str(year) for year in sorted(tables_df['league_season'].unique().tolist())]\n",
    "    year_selector_dropdown = Dropdown(label='Year', menu=year_labels, width_policy='min')\n",
    "    \n",
    "    slider_update_partial = partial(slider_update, lines_data_source=lines_data_source, bar_data_source=bar_data_source)\n",
    "    year_selector_update_partial = partial(year_selector_update, \n",
    "                                           lines_data_source=lines_data_source, \n",
    "                                           bar_data_source=bar_data_source, \n",
    "                                           bar_graph_object=bar_graph, \n",
    "                                           line_graph_object=line_graph, \n",
    "                                           round_slider_object=round_slider)\n",
    "    \n",
    "    round_slider.on_change('value', slider_update_partial)\n",
    "    year_selector_dropdown.on_click(year_selector_update_partial)\n",
    "\n",
    "    return column(row(bar_graph, line_graph, year_selector_dropdown), round_slider)\n",
    "    \n",
    "    \n",
    "def modify_doc(doc):\n",
    "    doc.add_root(create_bokeh_plot_for_round(tables_df, 1))\n",
    "    \n",
    "show(modify_doc, notebook_url=notebook_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8161ce6",
   "metadata": {},
   "source": [
    "<p>With these plots it's fairly easy to see the spread of team performances and how they accumulate points. There's the contenders: the small handful of teams near the top that are more likely than not to earn full points in a given week. Teams in the middle of the table have about even odds of doing the same. And then there's the teams in the relegation zone, who are lucky if they walk away from a match with a win.</p>\n",
    "\n",
    "<p>I've opted to keep the teams in the bar chart ordered by their final positions in the league table. This helps identify teams that are momentarily overperforming or underperforming, as they'll stand out from adjacent teams. For example, by match week 35 in the 2018 EPL season Watford seemed poised for at least a top half finish. Advance the slider through the rest of the season and you'll see that they managed to earn zero points in three games and ended the season in eleventh. Similarly, you can see how Newcastle managed to turn things around in the same year, after being level with Huddersfield in last place in week 10 they managed to pull things together enough to finish thirteenth. Huddersfield stayed last by a wide margin and were ultimately relegated.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb8f7e3",
   "metadata": {},
   "source": [
    "<p>Despite telling a few stories quite plainly, the graphs above hide a lot of nuance in their clutter. To move into the finer details of teams' performances, I'll create a few more columns in the table data. I'll make both a forward and backwards looking average points per game (ppg) column, and a pair of columns that flag a particular match as being a \"bad loss\" or a \"big win.\" These I'll define big wins and bad losses as being games where the goal difference was four or more.</p>\n",
    "\n",
    "<p>I also create a metric to judge team performance called \"{n}_match_ppg_diff.\" This is the difference between the  average points per game earned by a team over their next n games and the average from their previous {n} games. This helps control for varying team performance levels- some teams have higher baseline ppgs than others, so we really care more about deviations from the norm. I can also test different values of n to see if the effects of a big win or a bad loss are more visible when using certain metrics.</p>\n",
    "\n",
    "<p>I'll be running tests on these ppg_diff distributions to see if certain occurrences produce a statistically significant difference. I'll treat these distributions as samples of a larger super-population that is larger than just the table data. To me, the total population would the set of results where each team played each game both under \"treatment\" conditions and control conditions, with all other circumstances held equal. For example, when testing whether a late game impacts team performance, this hypothetical total population contains two results for each game in the league schedule, one where the game was played at night, and one where it was played during the day under otherwise equal conditions.</p>\n",
    "\n",
    "<p>Such a hypothetical population is impossible to actually realize, but has precedent [1, 2]</p>\n",
    "\n",
    "<p>\n",
    "[1] Hartley, H. O., and R. L. Sielken. “A ‘Super-Population Viewpoint’ for Finite Population Sampling.” Biometrics 31, no. 2 (June 1975): 411–22. https://doi.org/10.2307/2529429.\n",
    "\n",
    "[2] Gelman, Andrew. “Statistical Modeling, Causal Inference, and Social Science.” Statistical Modeling Causal Inference and Social Science. Columbia University, July 3, 2009. https://statmodeling.stat.columbia.edu/2009/07/03/how_does_statis/. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb395b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def _create_rolling_avg_match_pts(group: pd.DataFrame, period: int):\n",
    "    \"\"\"\n",
    "    Creates two new columns in the group named prev_{period}_match_ppg_avg and next_{period}_match_ppg_avg where\n",
    "        {period} is the second positional argument provided and represents the size of the rolling average to use.\n",
    "\n",
    "        The new columns represent the backwards and forwards looking moving averages of the points earned per game\n",
    "\n",
    "    Args:\n",
    "        group (DataFrame): team_id group of DataFrame generated by create_tables_df\n",
    "        period (int): The size of the rolling window\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with the two new columns\n",
    "\n",
    "    \"\"\"\n",
    "    group = group.sort_values(by='round')\n",
    "\n",
    "    group[f'prev_{period}_match_ppg_avg'] = group['match_pts'] \\\n",
    "        .shift(1) \\\n",
    "        .rolling(window=period, min_periods=period) \\\n",
    "        .mean()\n",
    "\n",
    "    group[f'next_{period}_match_ppg_avg'] = group[::-1]['match_pts'] \\\n",
    "        .shift(1) \\\n",
    "        .rolling(window=period, min_periods=period) \\\n",
    "        .mean()\n",
    "    return group\n",
    "\n",
    "\n",
    "def run_gd_statistical_test_for_period(epl_tables_df, period=3, by_team=False, big_win_goal_diff_thresh=4):\n",
    "    epl_tables_df = epl_tables_df.groupby(by=['league_season', 'team_id']).apply(_create_rolling_avg_match_pts,\n",
    "                                                                                 period=period)\n",
    "    epl_tables_df = epl_tables_df.dropna()\n",
    "    epl_tables_df[f'{period}_match_ppg_diff'] = \\\n",
    "        epl_tables_df[f'prev_{period}_match_ppg_avg'] - epl_tables_df[f'next_{period}_match_ppg_avg']\n",
    "\n",
    "    epl_tables_df['big_win'] = epl_tables_df['match_gd_full'] >= big_win_goal_diff_thresh\n",
    "    epl_tables_df['bad_loss'] = epl_tables_df['match_gd_full'] <= -big_win_goal_diff_thresh\n",
    "\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    if by_team:\n",
    "        for team_name in epl_tables_df['team_name'].unique():\n",
    "            big_win_group = epl_tables_df.loc[epl_tables_df['big_win'] & (epl_tables_df['team_name'] == team_name)]\n",
    "            bad_loss_group = epl_tables_df.loc[\n",
    "                epl_tables_df['bad_loss'] & (epl_tables_df['team_name'] == team_name)]\n",
    "            control_group = epl_tables_df.loc[(~epl_tables_df['big_win'])\n",
    "                                              & (~epl_tables_df['bad_loss'])\n",
    "                                              & (epl_tables_df['team_name'] == team_name)]\n",
    "            \n",
    "            control_group_ppg_mean = np.mean(control_group[f'{period}_match_ppg_diff'])\n",
    "            control_group_ppg_std = np.std(control_group[f'{period}_match_ppg_diff'])\n",
    "\n",
    "            if len(bad_loss_group) != 0:\n",
    "                _, bad_loss_p_value = stats.mannwhitneyu(bad_loss_group[f'{period}_match_ppg_diff'],\n",
    "                                                         control_group[f'{period}_match_ppg_diff'])\n",
    "                \n",
    "                bad_loss_ppg_mean = np.mean(bad_loss_group[f'{period}_match_ppg_diff'])\n",
    "                bad_loss_ppg_std = np.std(bad_loss_group[f'{period}_match_ppg_diff'])\n",
    "            else:\n",
    "                bad_loss_p_value = np.nan\n",
    "                bad_loss_ppg_mean = np.nan\n",
    "                bad_loss_ppg_std = np.nan\n",
    "\n",
    "            if len(big_win_group) != 0:\n",
    "                _, big_win_p_value = stats.mannwhitneyu(big_win_group[f'{period}_match_ppg_diff'],\n",
    "                                                        control_group[f'{period}_match_ppg_diff'])\n",
    "                \n",
    "                big_win_ppg_mean = np.mean(big_win_group[f'{period}_match_ppg_diff'])\n",
    "                big_win_ppg_std = np.std(big_win_group[f'{period}_match_ppg_diff'])\n",
    "            else:\n",
    "                big_win_p_value = np.nan\n",
    "                big_win_ppg_mean = np.nan\n",
    "                big_win_ppg_std = np.nan\n",
    "\n",
    "            results_df = pd.concat([results_df, pd.Series({\n",
    "                'team_name': team_name,\n",
    "                'period': period,\n",
    "                'control_group_mean': control_group_ppg_mean,\n",
    "                'control_group_std': control_group_ppg_std,\n",
    "                'bad_loss_n': len(bad_loss_group),\n",
    "                'bad_loss_p_value': bad_loss_p_value,\n",
    "                'bad_loss_mean': bad_loss_ppg_mean,\n",
    "                'bad_loss_std': bad_loss_ppg_std,\n",
    "                'big_win_n': len(big_win_group),\n",
    "                'big_win_p_value': big_win_p_value,\n",
    "                'big_win_mean': big_win_ppg_mean,\n",
    "                'big_win_std': big_win_ppg_std,\n",
    "            })], axis=1)\n",
    "\n",
    "        return results_df.transpose()\n",
    "    else:\n",
    "        big_win_group = epl_tables_df.loc[epl_tables_df['big_win']]\n",
    "        bad_loss_group = epl_tables_df.loc[epl_tables_df['bad_loss']]\n",
    "        control_group = epl_tables_df.loc[(~epl_tables_df['big_win']) & (~epl_tables_df['bad_loss'])]\n",
    "\n",
    "        _, bad_loss_p_value = stats.mannwhitneyu(bad_loss_group[f'{period}_match_ppg_diff'],\n",
    "                                                 control_group[f'{period}_match_ppg_diff'])\n",
    "        _, big_win_p_value = stats.mannwhitneyu(big_win_group[f'{period}_match_ppg_diff'],\n",
    "                                                control_group[f'{period}_match_ppg_diff'])\n",
    "        \n",
    "                    \n",
    "        control_group_ppg_mean = np.mean(control_group[f'{period}_match_ppg_diff'])\n",
    "        control_group_ppg_std = np.std(control_group[f'{period}_match_ppg_diff'])\n",
    "        \n",
    "        bad_loss_ppg_mean = np.mean(bad_loss_group[f'{period}_match_ppg_diff'])\n",
    "        bad_loss_ppg_std = np.std(bad_loss_group[f'{period}_match_ppg_diff'])\n",
    "\n",
    "        big_win_ppg_mean = np.mean(big_win_group[f'{period}_match_ppg_diff'])\n",
    "        big_win_ppg_std = np.std(big_win_group[f'{period}_match_ppg_diff'])\n",
    "\n",
    "        results_df = pd.Series({\n",
    "            'period': period,\n",
    "            'bad_loss_n': len(bad_loss_group),\n",
    "            'bad_loss_p_value': bad_loss_p_value,\n",
    "            'big_win_n': len(big_win_group),\n",
    "            'big_win_p_value': big_win_p_value,\n",
    "            'control_group_mean': control_group_ppg_mean,\n",
    "            'control_group_std': control_group_ppg_std,\n",
    "            'bad_loss_mean': bad_loss_ppg_mean,\n",
    "            'bad_loss_std': bad_loss_ppg_std,\n",
    "            'big_win_mean': big_win_ppg_mean,\n",
    "            'big_win_std': big_win_ppg_std\n",
    "        }).to_frame()\n",
    "\n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d504b6",
   "metadata": {},
   "source": [
    "<p>I test five different values of n: [1, 2, 3, 4, 5]. First I try and see if there is a difference in performance when testing the entire league at once, then I perform the test one team at a time. This results in a large total number of tests, so I also find the FDR-corrected p-values using the Benjamini/Hochberg correction.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d9618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.multitest\n",
    "\n",
    "metric_test_range = range(1, 6)\n",
    "\n",
    "gd_res_entire_league = pd.concat([run_gd_statistical_test_for_period(tables_df, period=period_length, by_team=False)\n",
    "          for period_length in metric_test_range], axis=1).transpose().reset_index(drop=True)\n",
    "\n",
    "gd_res_entire_league['adjusted_big_win_p_value'] = statsmodels.stats.multitest.fdrcorrection(gd_res_entire_league['big_win_p_value'], is_sorted=False)[1]\n",
    "gd_res_entire_league['adjusted_bad_loss_p_value'] = statsmodels.stats.multitest.fdrcorrection(gd_res_entire_league['bad_loss_p_value'], is_sorted=False)[1]\n",
    "\n",
    "gd_res_entire_league.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_res_by_team = pd.concat([run_gd_statistical_test_for_period(tables_df, period=period_length, by_team=True)\n",
    "          for period_length in metric_test_range], axis=0).dropna().reset_index(drop=True)\n",
    "\n",
    "gd_res_by_team['adjusted_big_win_p_value'] = statsmodels.stats.multitest.fdrcorrection(gd_res_by_team['big_win_p_value'], is_sorted=False)[1]\n",
    "gd_res_by_team['adjusted_bad_loss_p_value'] = statsmodels.stats.multitest.fdrcorrection(gd_res_by_team['bad_loss_p_value'], is_sorted=False)[1]\n",
    "\n",
    "gd_res_by_team.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb81429",
   "metadata": {},
   "source": [
    "<p>Next are a series of visualizations to show the results, first of the league-level test, then of each individual team. The visualizations display the uncorrected p-values at each tested metric horizon.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.palettes import Category10\n",
    "from bokeh.models import CheckboxGroup\n",
    "\n",
    "gd_entire_league_line_graph = figure(x_range=(min(metric_test_range), max(metric_test_range)),\n",
    "                    y_range=(0, 1),\n",
    "                    x_axis_label='Metric Horizon',\n",
    "                    y_axis_label='P-Value',\n",
    "                    toolbar_location=None,\n",
    "                    plot_width=2 * plot_size,\n",
    "                    plot_height=plot_size,\n",
    "                    title='Big Win and Bad Loss Test Results at Various Metric Horizons Entire League')\n",
    "\n",
    "gd_league_bad_loss_lines_data_source = ColumnDataSource(\n",
    "    dict(\n",
    "        xs=[gd_res_entire_league['period'], gd_res_entire_league['period']],\n",
    "        ys=[gd_res_entire_league['big_win_p_value'], gd_res_entire_league['bad_loss_p_value']],\n",
    "        line_colors=Category10[3][:2],\n",
    "        series_labels=['Big Win', 'Bad Loss']\n",
    "    )\n",
    ")\n",
    "\n",
    "gd_league_bad_loss_scatter_data_source = ColumnDataSource(\n",
    "    dict(\n",
    "        x=gd_res_entire_league['period'].tolist() + gd_res_entire_league['period'].tolist(),\n",
    "        y=gd_res_entire_league['big_win_p_value'].tolist() + gd_res_entire_league['bad_loss_p_value'].tolist(),\n",
    "        scatter_colors=[Category10[3][0]] * len(gd_res_entire_league) + [Category10[3][1]] * len(gd_res_entire_league)\n",
    "    )\n",
    ")\n",
    "\n",
    "gd_entire_league_line_graph.multi_line(xs='xs', ys='ys', line_color='line_colors', legend_field='series_labels', line_width=2, source=gd_league_bad_loss_lines_data_source)\n",
    "gd_entire_league_line_graph.scatter(x='x', y='y', size=15, fill_color='scatter_colors', line_color='scatter_colors', source=gd_league_bad_loss_scatter_data_source)\n",
    "\n",
    "def modify_doc_gd_entire_league_p_value(doc):\n",
    "    doc.add_root(gd_entire_league_line_graph)\n",
    "    \n",
    "show(modify_doc_gd_entire_league_p_value, notebook_url=notebook_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_wins_by_team_line_graph = figure(\n",
    "                    x_range=(min(metric_test_range), max(metric_test_range)),\n",
    "                    y_range=(0, 1),\n",
    "                    x_axis_label='Metric Horizon',\n",
    "                    y_axis_label='P-Value',\n",
    "                    toolbar_location=None,\n",
    "                    plot_width=2 * plot_size,\n",
    "                    plot_height=round(1.5 * plot_size),\n",
    "                    title='Big Win Test Results at Various Metric Horizons By Team')\n",
    "\n",
    "team_names = gd_res_by_team['team_name'].unique()\n",
    "\n",
    "n_teams = len(team_names)\n",
    "\n",
    "team_dfs = [group[1] for group in gd_res_by_team.groupby(by=['team_name'])]\n",
    "\n",
    "def update_data_sources_for_activated_teams(activated_teams, lines_data_source, scatter_data_source, metric_to_plot):\n",
    "    big_wins_xs = list()\n",
    "    big_wins_ys = list()\n",
    "    big_wins_line_colors = list()\n",
    "    big_wins_series_labels = list()\n",
    "\n",
    "    big_wins_scatter_xs = list()\n",
    "    big_wins_scatter_ys = list()\n",
    "    big_wins_scatter_colors = list()\n",
    "\n",
    "    for df in [df for df in team_dfs if df['team_name'].iloc[0] in activated_teams]:\n",
    "        team_color = tables_df.loc[tables_df['team_name'] == df['team_name'].iloc[0]]['team_color'].iloc[0]\n",
    "\n",
    "        big_wins_xs.append(df['period'])\n",
    "        big_wins_ys.append(df[metric_to_plot])\n",
    "        big_wins_line_colors.append(team_color)\n",
    "        big_wins_series_labels.append(df['team_name'].iloc[0])\n",
    "\n",
    "        big_wins_scatter_xs.extend(df['period'])\n",
    "        big_wins_scatter_ys.extend(df[metric_to_plot])\n",
    "        big_wins_scatter_colors.extend([team_color] * len(df))\n",
    "    \n",
    "    lines_data_source.data = dict(\n",
    "        xs=big_wins_xs,\n",
    "        ys=big_wins_ys,\n",
    "        line_colors=big_wins_line_colors,\n",
    "        series_labels=big_wins_series_labels\n",
    "    )\n",
    "\n",
    "    scatter_data_source.data = dict(\n",
    "        x=big_wins_scatter_xs,\n",
    "        y=big_wins_scatter_ys,\n",
    "        scatter_colors=big_wins_scatter_colors\n",
    "    )\n",
    "    \n",
    "big_win_by_team_lines_data_source = ColumnDataSource(\n",
    "    dict(\n",
    "        xs=list(),\n",
    "        ys=list(),\n",
    "        line_colors=list(),\n",
    "        series_labels=list(),\n",
    "    )\n",
    ")\n",
    "\n",
    "big_win_by_team_scatter_data_source = ColumnDataSource(\n",
    "    dict(\n",
    "        x=list(),\n",
    "        y=list(),\n",
    "        scatter_colors=list()\n",
    "    )\n",
    ")\n",
    "\n",
    "big_wins_by_team_line_graph.multi_line(xs='xs', ys='ys', line_color='line_colors', legend_field='series_labels', line_width=2, source=big_win_by_team_lines_data_source)\n",
    "big_wins_by_team_line_graph.scatter(x='x', y='y', size=8, fill_color='scatter_colors', line_color='scatter_colors', source=big_win_by_team_scatter_data_source)\n",
    "\n",
    "checkbox_labels=sorted(team_names.tolist())\n",
    "\n",
    "def checkbox_group_on_click(event):\n",
    "    activated_team_names = [checkbox_labels[i] for i in event]\n",
    "    update_data_sources_for_activated_teams(activated_team_names, big_win_by_team_lines_data_source, big_win_by_team_scatter_data_source, metric_to_plot='big_win_p_value')\n",
    "\n",
    "checkbox_group = CheckboxGroup(labels=checkbox_labels)\n",
    "checkbox_group.on_click(checkbox_group_on_click)\n",
    "\n",
    "def modify_doc_gd_by_team_p_value(doc):\n",
    "    doc.add_root(row(big_wins_by_team_line_graph, checkbox_group))\n",
    "    \n",
    "show(modify_doc_gd_by_team_p_value, notebook_url=notebook_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135facf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_loss_by_team_line_graph = figure(\n",
    "                    x_range=(min(metric_test_range), max(metric_test_range)),\n",
    "                    y_range=(0, 1),\n",
    "                    x_axis_label='Metric Horizon',\n",
    "                    y_axis_label='P-Value',\n",
    "                    toolbar_location=None,\n",
    "                    plot_width=2 * plot_size,\n",
    "                    plot_height=round(1.5 * plot_size),\n",
    "                    title='Bad Loss Test Results at Various Metric Horizons By Team')\n",
    "    \n",
    "big_loss_by_team_lines_data_source = ColumnDataSource(\n",
    "    dict(\n",
    "        xs=list(),\n",
    "        ys=list(),\n",
    "        line_colors=list(),\n",
    "        series_labels=list(),\n",
    "    )\n",
    ")\n",
    "\n",
    "big_loss_by_team_scatter_data_source = ColumnDataSource(\n",
    "    dict(\n",
    "        x=list(),\n",
    "        y=list(),\n",
    "        scatter_colors=list()\n",
    "    )\n",
    ")\n",
    "\n",
    "big_loss_by_team_line_graph.multi_line(xs='xs', ys='ys', line_color='line_colors', legend_field='series_labels', line_width=2, source=big_loss_by_team_lines_data_source)\n",
    "big_loss_by_team_line_graph.scatter(x='x', y='y', size=8, fill_color='scatter_colors', line_color='scatter_colors', source=big_loss_by_team_scatter_data_source)\n",
    "\n",
    "checkbox_labels=sorted(team_names.tolist())\n",
    "\n",
    "def checkbox_group_on_click(event):\n",
    "    activated_team_names = [checkbox_labels[i] for i in event]\n",
    "    update_data_sources_for_activated_teams(activated_team_names, big_loss_by_team_lines_data_source, big_loss_by_team_scatter_data_source, metric_to_plot='bad_loss_p_value')\n",
    "\n",
    "big_loss_checkbox_group = CheckboxGroup(labels=checkbox_labels)\n",
    "big_loss_checkbox_group.on_click(checkbox_group_on_click)\n",
    "\n",
    "def modify_doc_gd_big_loss_by_team_p_value(doc):\n",
    "    doc.add_root(row(big_loss_by_team_line_graph, big_loss_checkbox_group))\n",
    "    \n",
    "show(modify_doc_gd_big_loss_by_team_p_value, notebook_url=notebook_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe67f0",
   "metadata": {},
   "source": [
    "<p>These charts suggest that there are very few teams whose performance varies in a statistically significant way after a big win and a bad loss. A more robust filtering of the test results confirms this. First we can take a look at the differences in performance after a big win:<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_res_by_team.loc[gd_res_by_team['big_win_p_value'] < 0.05] \\\n",
    "    [['team_name', 'period', 'big_win_n', 'big_win_p_value', 'adjusted_big_win_p_value', 'big_win_mean', 'big_win_std', 'control_group_mean', 'control_group_std']] \\\n",
    "    .sort_values(by=['team_name', 'period']).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71740ebb",
   "metadata": {},
   "source": [
    "<p>It looks like only Arsenal and Manchester United had statistically significant differences in their performances. Fulham's \"big win\" sample size appears too small to be meaningful. For both Arsenal and Manchester United, however, the adjusted p-values (q-values) reveal that these results are above our FDR threshold of q=0.05.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca4d513",
   "metadata": {},
   "source": [
    "<p>Next we look for statistically significant differences after a bad loss:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbebd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_res_by_team.loc[gd_res_by_team['bad_loss_p_value'] < 0.05] \\\n",
    "    [['team_name', 'period', 'big_win_n', 'big_win_p_value', 'big_win_mean', 'big_win_std', 'control_group_mean', 'control_group_std']] \\\n",
    "    .sort_values(by=['team_name', 'period']).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced58e06",
   "metadata": {},
   "source": [
    "<p>A few teams exhibit a statistically significant difference in points per game, but in all cases the sample sizes for what can be considered the treatment group are too small to be meaningful.</p>\n",
    "\n",
    "<p>Next I test to see if late games have an adverse effect on teams. I count a game as \"late\" if it starts after 6:00pm local time, and I run a chi squared contingency test on the counts of the three possible game outcomes (a win, loss, or draw) between the control and the treatment group. I do this once per team, and run the p-value correction again.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e99726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tod_statistical_test_for_period(epl_tables_df, late_game_hour_cutoff=18):\n",
    "    epl_tables_df['fixture_hour'] = epl_tables_df['fixture_date'].apply(lambda date: date.hour)\n",
    "    epl_tables_df['late_game'] = epl_tables_df['fixture_hour'] >= late_game_hour_cutoff\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "    for team_name in epl_tables_df['team_name'].unique():\n",
    "        late_game_group = epl_tables_df.loc[epl_tables_df['late_game'] & (epl_tables_df['team_name'] == team_name)]\n",
    "        control_group = epl_tables_df.loc[(~epl_tables_df['late_game']) & (epl_tables_df['team_name'] == team_name)]\n",
    "\n",
    "        late_game_outcomes = late_game_group.groupby('match_pts').apply(len).tolist()\n",
    "        control_game_outcomes = control_group.groupby('match_pts').apply(len).tolist()\n",
    "\n",
    "        if len(late_game_outcomes) == 3 and len(control_game_outcomes) == 3:\n",
    "            chi2, p_value, dof, expected = stats.chi2_contingency(\n",
    "                np.array([late_game_outcomes, control_game_outcomes])\n",
    "            )\n",
    "        else:\n",
    "            p_value = np.nan\n",
    "            chi2 = np.nan\n",
    "            dof = np.nan\n",
    "\n",
    "        result_df = pd.concat([result_df, pd.Series({\n",
    "            'team_name': team_name,\n",
    "            'n': len(late_game_group),\n",
    "            'p_value': p_value,\n",
    "            'chi_2': chi2,\n",
    "            'dof': dof\n",
    "        })], axis=1)\n",
    "\n",
    "    return result_df.transpose().sort_values(by='p_value')\n",
    "\n",
    "tod_test_results = run_tod_statistical_test_for_period(tables_df)\n",
    "tod_test_results.sort_values(by='p_value', ascending=True).head()\n",
    "tod_test_results['adjusted_p_value'] = statsmodels.stats.multitest.fdrcorrection(tod_test_results['p_value'], is_sorted=True)[1]\n",
    "\n",
    "tod_test_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b860d",
   "metadata": {},
   "source": [
    "<p>It looks like in the ten year stretch that our data covers, only Watford had a statistically different performance between games they played during the day and those they played in the evening. Again, however, the q-value falls outside the acceptable range. Still, we can plot the win/draw/loss distribution for the two match groups and examine the differences:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_game_graph = figure(title=f'Watford Early Day Games W/D/L Distribution 2011-2021',\n",
    "                        y_axis_label='Frequency',\n",
    "                        x_range=['Win', 'Draw', 'Loss'],\n",
    "                        toolbar_location=None,\n",
    "                        plot_width=plot_size,\n",
    "                        plot_height=plot_size)\n",
    "\n",
    "late_game_graph = figure(title=f'Watford Late Day Games W/D/L Distribution 2011-2021',\n",
    "                        y_axis_label='Frequency',\n",
    "                        x_range=['Win', 'Draw', 'Loss'],\n",
    "                        toolbar_location=None,\n",
    "                        plot_width=plot_size,\n",
    "                        plot_height=plot_size)\n",
    "\n",
    "early_game_graph.toolbar.active_drag = None\n",
    "early_game_graph.toolbar.active_scroll = None\n",
    "early_game_graph.toolbar.active_tap = None\n",
    "early_game_graph.y_range.start = 0\n",
    "early_game_graph.xgrid.grid_line_color = None\n",
    "\n",
    "late_game_graph.toolbar.active_drag = None\n",
    "late_game_graph.toolbar.active_scroll = None\n",
    "late_game_graph.toolbar.active_tap = None\n",
    "late_game_graph.y_range.start = 0\n",
    "late_game_graph.xgrid.grid_line_color = None\n",
    "\n",
    "watford_early_games_df = tables_df.loc[\n",
    "    (tables_df['team_name'] == 'Watford') & ~(tables_df['late_game'])\n",
    "]\n",
    "\n",
    "watford_late_games_df = tables_df.loc[\n",
    "    (tables_df['team_name'] == 'Watford') & (tables_df['late_game'])\n",
    "]\n",
    "\n",
    "watford_early_games_results = watford_early_games_df.groupby('match_pts').apply(len)\n",
    "n_early_games = len(watford_early_games_df)\n",
    "\n",
    "watford_early_games_losses = watford_early_games_results[0] / n_early_games\n",
    "watford_early_games_draws = watford_early_games_results[1] / n_early_games\n",
    "watford_early_games_wins = watford_early_games_results[3] / n_early_games\n",
    "\n",
    "watford_late_games_results = watford_late_games_df.groupby('match_pts').apply(len)\n",
    "n_late_games = len(watford_late_games_df)\n",
    "\n",
    "watford_late_games_losses = watford_late_games_results[0] / n_late_games\n",
    "watford_late_games_draws = watford_late_games_results[1] / n_late_games\n",
    "watford_late_games_wins = watford_late_games_results[3] / n_late_games\n",
    "\n",
    "early_games_bar_data_source = ColumnDataSource(\n",
    "    dict(\n",
    "        x=['Win', 'Draw', 'Loss'],\n",
    "        y=[0] * 3,\n",
    "        top=[watford_early_games_wins, watford_early_games_draws, watford_early_games_losses],\n",
    "        color=[Category10[3][0]] * 3\n",
    "    )\n",
    ")\n",
    "\n",
    "late_games_bar_data_source = ColumnDataSource(\n",
    "    dict(\n",
    "        x=['Win', 'Draw', 'Loss'],\n",
    "        y=[0] * 3,\n",
    "        top=[watford_late_games_wins, watford_late_games_draws, watford_late_games_losses],\n",
    "        color=[Category10[3][1]] * 3\n",
    "    )\n",
    ")\n",
    "\n",
    "early_game_graph.vbar(x='x', top='top', color='color', source=early_games_bar_data_source)\n",
    "late_game_graph.vbar(x='x', top='top', color='color', source=late_games_bar_data_source)\n",
    "\n",
    "def modify_watford_late_games_test_p_value(doc):\n",
    "    doc.add_root(row(early_game_graph, late_game_graph))\n",
    "    \n",
    "show(modify_watford_late_games_test_p_value, notebook_url=notebook_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_games_avg_pts = np.mean(watford_early_games_df['match_pts'])\n",
    "early_games_pts_std_dev = np.std(watford_early_games_df['match_pts'])\n",
    "\n",
    "print(f'Early games average points earned: {early_games_avg_pts}, std. dev.:  {early_games_pts_std_dev}')\n",
    "\n",
    "late_games_avg_pts = np.mean(watford_late_games_df['match_pts'])\n",
    "late_games_pts_std_dev = np.std(watford_late_games_df['match_pts'])\n",
    "print(f'Late games average points earned: {late_games_avg_pts}, std. dev.:  {late_games_pts_std_dev}')\n",
    "\n",
    "print(f\"\\nCohen's effect size on points earned: {(early_games_avg_pts - late_games_avg_pts) / early_games_pts_std_dev}\")\n",
    "\n",
    "tod_test_N = n_early_games + n_late_games\n",
    "\n",
    "effect_size_phi = math.sqrt(tod_test_results.loc[tod_test_results['team_name'] == 'Watford']['chi_2'][0] / tod_test_N)\n",
    "\n",
    "print(f'Phi effect size: {effect_size_phi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f94be",
   "metadata": {},
   "source": [
    "<p>Last, I wanted to see if playing a game at a \"cold, rainy night at Stoke\" makes a statistically significant difference to game outcomes. To pick games that happen at night I again choose those that start after 6:00pm local time. For the \"cold\" part I use the time of year as a proxy, taking any games in November, December, January, and February as \"cold.\" The \"rainy\" element is unfortunately not possible for me to filter by using the current dataset as it doesn't provide weather data. Even if it did, I believe it would reduce the sample size by too much.</p>\n",
    "\n",
    "<p>If I tested only games that occurred under the above criteria in Stoke, then the treatment group would also be far too small. Instead, I hand-picked \"stoke-like\" teams that played in the league between 2011 and 2021. These teams will be my broader stand-in for Stoke. I chose teams that were from the Midlands or the North, were mid- to small- sized (no Manchester United, for example), and often played with a highly defensive, counter-attacking long ball and low block. For my control group I select the same teams though choose normal conditions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a77ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stoke_statistical_test(epl_tables_df, late_game_hour_cutoff=18, cold_season_start_month=11,\n",
    "                               cold_season_end_month=3):\n",
    "    epl_tables_df['fixture_hour'] = epl_tables_df['fixture_date'].apply(lambda date: date.hour)\n",
    "    epl_tables_df['fixture_month'] = epl_tables_df['fixture_date'].apply(lambda date: date.month)\n",
    "\n",
    "    epl_tables_df['late_game'] = epl_tables_df['fixture_hour'] >= late_game_hour_cutoff\n",
    "    epl_tables_df['cold_game'] = (epl_tables_df['fixture_month'] >= cold_season_start_month) | \\\n",
    "                                 (epl_tables_df['fixture_month'] < cold_season_end_month)\n",
    "\n",
    "    stoke_like = {'Blackburn': True,\n",
    "                  'Manchester United': False,\n",
    "                  'Chelsea': False,\n",
    "                  'Arsenal': False,\n",
    "                  'Wolves': False,\n",
    "                  'Norwich': False,\n",
    "                  'Bolton': True,\n",
    "                  'Sunderland': True,\n",
    "                  'Aston Villa': False,\n",
    "                  'Everton': False,\n",
    "                  'Swansea': False,\n",
    "                  'QPR': False,\n",
    "                  'West Brom': False,\n",
    "                  'Stoke City': True,\n",
    "                  'Newcastle': True,\n",
    "                  'Wigan': True,\n",
    "                  'Liverpool': False,\n",
    "                  'Fulham': False,\n",
    "                  'Manchester City': False,\n",
    "                  'Tottenham': False,\n",
    "                  'Southampton': False,\n",
    "                  'Reading': False,\n",
    "                  'West Ham': False,\n",
    "                  'Cardiff': False,\n",
    "                  'Hull City': True,\n",
    "                  'Crystal Palace': False,\n",
    "                  'Leicester': False,\n",
    "                  'Burnley': True,\n",
    "                  'Watford': False,\n",
    "                  'Bournemouth': False,\n",
    "                  'Middlesbrough': True,\n",
    "                  'Brighton': False,\n",
    "                  'Huddersfield': True,\n",
    "                  'Sheffield Utd': True,\n",
    "                  'Leeds': False,\n",
    "                  'Brentford': False}\n",
    "\n",
    "    epl_tables_df['stoke_like_opposition'] = epl_tables_df['opp_team_name'].apply(lambda name: stoke_like[name])\n",
    "\n",
    "    cold_rainy_nights_at_stoke_df = epl_tables_df.loc[\n",
    "        epl_tables_df['cold_game'] &\n",
    "        epl_tables_df['late_game'] &\n",
    "        epl_tables_df['stoke_like_opposition'] &\n",
    "        ~epl_tables_df['home']\n",
    "        ]\n",
    "\n",
    "    control_group = epl_tables_df.loc[\n",
    "        (~epl_tables_df['cold_game'] |\n",
    "        ~epl_tables_df['late_game']) &\n",
    "        (epl_tables_df['stoke_like_opposition'] &\n",
    "        ~epl_tables_df['home'])\n",
    "        ]\n",
    "\n",
    "    cold_rainy_nights_outcome = cold_rainy_nights_at_stoke_df.groupby('match_pts').apply(len).tolist()\n",
    "    control_game_outcomes = control_group.groupby('match_pts').apply(len).tolist()\n",
    "\n",
    "    chi2, p_value, dof, expected = stats.chi2_contingency(\n",
    "        np.array([cold_rainy_nights_outcome, control_game_outcomes])\n",
    "    )\n",
    "    \n",
    "    stoke_test_N = len(control_group) + len(cold_rainy_nights_at_stoke_df)\n",
    "    effect_size_phi = math.sqrt(chi2 / stoke_test_N)\n",
    "    \n",
    "    control_games_avg_pts = np.mean(control_group['match_pts'])\n",
    "    control_games_pts_std_dev = np.std(control_group['match_pts'])\n",
    "    \n",
    "    stoke_games_avg_pts = np.mean(cold_rainy_nights_at_stoke_df['match_pts'])\n",
    "    stoke_games_pts_std_dev = np.std(cold_rainy_nights_at_stoke_df['match_pts'])\n",
    "    \n",
    "    print(f'Control mean: {control_games_avg_pts}')\n",
    "    print(f'Stoke mean: {stoke_games_avg_pts}')\n",
    "    \n",
    "    cohens = (control_games_avg_pts - stoke_games_avg_pts) / max(control_games_pts_std_dev, stoke_games_pts_std_dev)\n",
    "\n",
    "    return p_value, cohens, effect_size_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoke_p_value, stoke_effect_size_cohens, stoke_effect_size_phi = run_stoke_statistical_test(tables_df)\n",
    "\n",
    "print(f'P-Value: {stoke_p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c293ef",
   "metadata": {},
   "source": [
    "<p>The result isn't statistically significant, making it unlikely that there is a systematic disadvantage to playing at a cold, rainy night over any other time at Stoke.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
